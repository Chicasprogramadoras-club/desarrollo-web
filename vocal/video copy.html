<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Detector de Vocales con Lenguaje de Señas</title>
    <style>
        #app-container {
            text-align: center;
            margin-top: 20px;
        }

        #webcam-container {
            margin-top: 20px;
        }
    </style>
</head>
<body>
    <div id="app-container">
        <h1>Detector de Vocales con Lenguaje de Señas</h1>
        <button type="button" onclick="init()">Iniciar</button>
        <div id="webcam-container"></div>
        <div id="label-container"></div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>
    <script>
        const URL = "./";
        let model, webcam, labelContainer, maxPredictions;

        // Load the image model and setup the webcam
        async function init() {
            const modelURL = URL + "model.json";
            const metadataURL = URL + "metadata.json";

            try {
                // load the model and metadata
                model = await tmImage.load(modelURL, metadataURL);
                maxPredictions = model.getTotalClasses();

                // Convenience function to setup a webcam
                const flip = true; // whether to flip the webcam
                webcam = new tmImage.Webcam(200, 200, flip); // width, height, flip
                await webcam.setup(); // request access to the webcam
                await webcam.play();
                window.requestAnimationFrame(loop);

                // append elements to the DOM
                document.getElementById("webcam-container").appendChild(webcam.canvas);
                labelContainer = document.getElementById("label-container");
                for (let i = 0; i < maxPredictions; i++) { // and class labels
                    labelContainer.appendChild(document.createElement("div"));
                }
            } catch (error) {
                console.error("Error al cargar el modelo:", error);
                alert("Error al cargar el modelo. Por favor, vuelva a intentarlo.");
            }
        }

        async function loop() {
            webcam.update(); // update the webcam frame
            await predict();
            window.requestAnimationFrame(loop);
        }

        // run the webcam image through the image model
        async function predict() {
            try {
                // predict can take in an image, video, or canvas html element
                const prediction = await model.predict(webcam.canvas);

                // Define las vocales y sus umbrales de probabilidad
                const vowels = ['A', 'E', 'I', 'O', 'U'];
                const vowelThreshold = 0.8; // Ajusta según tu necesidad

                // Iterar sobre las predicciones
                for (let i = 0; i < maxPredictions; i++) {
                    const className = prediction[i].className;
                    const probability = prediction[i].probability.toFixed(2);

                    // Comparar con las vocales y hablar la vocal correspondiente
                    if (vowels.includes(className) && probability > vowelThreshold) {
                        speakVowel(className);
                    }

                    // Actualizar la interfaz con la predicción
                    const classPrediction = `${className}: ${probability}`;
                    labelContainer.childNodes[i].innerHTML = classPrediction;
                }
            } catch (error) {
                console.error("Error al realizar la predicción:", error);
            }
        }

        function speakVowel(vowel) {
            const utterance = new SpeechSynthesisUtterance(`La vocal detectada es ${vowel}`);
            window.speechSynthesis.speak(utterance);
        }
    </script>
</body>
</html>
